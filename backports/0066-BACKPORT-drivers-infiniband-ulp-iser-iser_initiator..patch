From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/ulp/iser/iser_initiator.c

Change-Id: I4770154627874a4bc0ecabd7f144cd2e2be4dbbb
---
 drivers/infiniband/ulp/iser/iser_initiator.c | 41 ++++++++++++++++----
 1 file changed, 33 insertions(+), 8 deletions(-)

--- a/drivers/infiniband/ulp/iser/iser_initiator.c
+++ b/drivers/infiniband/ulp/iser/iser_initiator.c
@@ -37,7 +37,6 @@
 #include <linux/kfifo.h>
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_host.h>
-
 #include "iscsi_iser.h"
 
 /* Register user buffer memory and initialize passive rdma
@@ -643,7 +642,6 @@ static int iser_check_remote_inv(struct
 	return 0;
 }
 
-
 void iser_task_rsp(struct ib_cq *cq, struct ib_wc *wc)
 {
 	struct ib_conn *ib_conn = wc->qp->qp_context;
@@ -746,12 +744,27 @@ void iser_task_rdma_init(struct iscsi_is
 void iser_task_rdma_finalize(struct iscsi_iser_task *iser_task)
 {
 	int prot_count = scsi_prot_sg_count(iser_task->sc);
+#ifndef HAVE_VIRT_BOUNDARY
+	bool is_rdma_data_aligned;
+#endif
 
 	if (iser_task->dir[ISER_DIR_IN]) {
+#ifndef HAVE_VIRT_BOUNDARY
+		is_rdma_data_aligned = true;
+		if (iser_task->data[ISER_DIR_IN].orig_sg) {
+			iser_finalize_rdma_unaligned_sg(iser_task,
+							&iser_task->data[ISER_DIR_IN],
+							ISER_DIR_IN);
+			is_rdma_data_aligned = false;
+		}
+#endif
 		iser_unreg_mem_fastreg(iser_task, ISER_DIR_IN);
-		iser_dma_unmap_task_data(iser_task,
-					 &iser_task->data[ISER_DIR_IN],
-					 DMA_FROM_DEVICE);
+#ifndef HAVE_VIRT_BOUNDARY
+		if (is_rdma_data_aligned)
+#endif
+			iser_dma_unmap_task_data(iser_task,
+						 &iser_task->data[ISER_DIR_IN],
+						 DMA_FROM_DEVICE);
 		if (prot_count)
 			iser_dma_unmap_task_data(iser_task,
 						 &iser_task->prot[ISER_DIR_IN],
@@ -759,10 +772,22 @@ void iser_task_rdma_finalize(struct iscs
 	}
 
 	if (iser_task->dir[ISER_DIR_OUT]) {
+#ifndef HAVE_VIRT_BOUNDARY
+		is_rdma_data_aligned = true;
+		if (iser_task->data[ISER_DIR_OUT].orig_sg) {
+			iser_finalize_rdma_unaligned_sg(iser_task,
+							&iser_task->data[ISER_DIR_OUT],
+							ISER_DIR_OUT);
+			is_rdma_data_aligned = false;
+		}
+#endif
 		iser_unreg_mem_fastreg(iser_task, ISER_DIR_OUT);
-		iser_dma_unmap_task_data(iser_task,
-					 &iser_task->data[ISER_DIR_OUT],
-					 DMA_TO_DEVICE);
+#ifndef HAVE_VIRT_BOUNDARY
+		if (is_rdma_data_aligned)
+#endif
+			iser_dma_unmap_task_data(iser_task,
+						 &iser_task->data[ISER_DIR_OUT],
+						 DMA_TO_DEVICE);
 		if (prot_count)
 			iser_dma_unmap_task_data(iser_task,
 						 &iser_task->prot[ISER_DIR_OUT],
