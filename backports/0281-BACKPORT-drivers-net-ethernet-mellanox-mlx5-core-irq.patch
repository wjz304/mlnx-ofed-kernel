From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT:
 drivers/net/ethernet/mellanox/mlx5/core/irq_affinity.c

Change-Id: I2811c0a3010eca033558e7c4fcfbdbcc09934327
---
 .../mellanox/mlx5/core/irq_affinity.c         | 22 ++++++++++++++++++-
 1 file changed, 21 insertions(+), 1 deletion(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/irq_affinity.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/irq_affinity.c
@@ -152,10 +152,15 @@ mlx5_irq_affinity_request(struct mlx5_ir
 out:
 	mlx5_irq_get_locked(least_loaded_irq);
 	if (mlx5_irq_read_locked(least_loaded_irq) > pool->max_threshold)
+#ifdef HAVE_PCI_IRQ_API
 		mlx5_core_dbg(pool->dev, "IRQ %u overloaded, pool_name: %s, %u EQs on this irq\n",
 			      pci_irq_vector(pool->dev->pdev,
 					     mlx5_irq_get_index(least_loaded_irq)), pool->name,
 			      mlx5_irq_read_locked(least_loaded_irq) / MLX5_EQ_REFS_PER_IRQ);
+#else
+		mlx5_core_dbg(pool->dev, "IRQ overloaded, pool_name: %s, %u EQs on this irq\n",
+			      pool->name, mlx5_irq_read_locked(least_loaded_irq) / MLX5_EQ_REFS_PER_IRQ);
+#endif
 unlock:
 	mutex_unlock(&pool->lock);
 	return least_loaded_irq;
@@ -166,12 +171,21 @@ void mlx5_irq_affinity_irqs_release(stru
 {
 	struct mlx5_irq_pool *pool = mlx5_irq_pool_get(dev);
 	int i;
+#ifndef HAVE_PCI_IRQ_API
+        struct mlx5_priv* priv = &dev->priv;
+#endif
+
 
 	for (i = 0; i < num_irqs; i++) {
 		int cpu = cpumask_first(mlx5_irq_get_affinity_mask(irqs[i]));
 
+#ifdef HAVE_PCI_IRQ_API
 		synchronize_irq(pci_irq_vector(pool->dev->pdev,
 					       mlx5_irq_get_index(irqs[i])));
+#else
+		int index = mlx5_irq_get_index(irqs[i]);
+		synchronize_irq(priv->msix_arr[index].vector);
+#endif
 		if (mlx5_irq_put(irqs[i]))
 			if (pool->irqs_per_cpu)
 				cpu_put(pool, cpu);
@@ -198,7 +212,7 @@ int mlx5_irq_affinity_irqs_request_auto(
 {
 	struct mlx5_irq_pool *pool = mlx5_irq_pool_get(dev);
 	cpumask_var_t req_mask;
-	struct mlx5_irq *irq;
+	struct mlx5_irq *irq = NULL;
 	int i = 0;
 
 	if (!zalloc_cpumask_var(&req_mask, GFP_KERNEL))
@@ -217,10 +231,16 @@ int mlx5_irq_affinity_irqs_request_auto(
 			break;
 		irqs[i] = irq;
 		cpumask_clear_cpu(cpumask_first(mlx5_irq_get_affinity_mask(irq)), req_mask);
+#ifdef HAVE_PCI_IRQ_API
 		mlx5_core_dbg(dev, "IRQ %u mapped to cpu %*pbl, %u EQs on this irq\n",
 			      pci_irq_vector(dev->pdev, mlx5_irq_get_index(irq)),
 			      cpumask_pr_args(mlx5_irq_get_affinity_mask(irq)),
 			      mlx5_irq_read_locked(irq) / MLX5_EQ_REFS_PER_IRQ);
+#else
+		mlx5_core_dbg(dev, "IRQ mapped to cpu %*pbl, %u EQs on this irq\n",
+			      cpumask_pr_args(mlx5_irq_get_affinity_mask(irq)),
+			      mlx5_irq_read_locked(irq) / MLX5_EQ_REFS_PER_IRQ);
+#endif
 	}
 	free_cpumask_var(req_mask);
 	if (!i)
