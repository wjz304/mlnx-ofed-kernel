From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/hw/mlx5/mlx5_ib.h

---
 drivers/infiniband/hw/mlx5/mlx5_ib.h | 23 +++++++++++++++++++----
 1 file changed, 19 insertions(+), 4 deletions(-)

--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -660,7 +660,7 @@ struct mlx5_ib_mkey {
 	u32 key;
 	enum mlx5_mkey_type type;
 	unsigned int ndescs;
-	struct wait_queue_head wait;
+	wait_queue_head_t wait;
 	refcount_t usecount;
 	/* User Mkey must hold either a rb_key or a cache_ent. */
 	struct mlx5r_cache_rb_key rb_key;
@@ -1297,8 +1297,11 @@ to_mmmap(struct rdma_user_mmap_entry *rd
 		struct mlx5_user_mmap_entry, rdma_entry);
 }
 
-int mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context, unsigned long virt,
-			struct mlx5_db *db);
+int mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context,
+#ifdef HAVE_BASECODE_EXTRAS
+			struct ib_udata *udata,
+#endif
+			unsigned long virt, struct mlx5_db *db);
 void mlx5_ib_db_unmap_user(struct mlx5_ib_ucontext *context, struct mlx5_db *db);
 void __mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq);
 void mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq);
@@ -1359,7 +1362,8 @@ int mlx5_ib_advise_mr(struct ib_pd *pd,
 int mlx5_ib_alloc_mw(struct ib_mw *mw, struct ib_udata *udata);
 int mlx5_ib_dealloc_mw(struct ib_mw *mw);
 struct mlx5_ib_mr *mlx5_ib_alloc_implicit_mr(struct mlx5_ib_pd *pd,
-					     int access_flags);
+					     struct ib_udata *udata,
+			  		     int access_flags);
 void mlx5_ib_free_implicit_mr(struct mlx5_ib_mr *mr);
 void mlx5_ib_free_odp_mr(struct mlx5_ib_mr *mr);
 struct ib_mr *mlx5_ib_rereg_user_mr(struct ib_mr *ib_mr, int flags, u64 start,
@@ -1437,6 +1441,10 @@ int mlx5r_odp_create_eq(struct mlx5_ib_d
 void mlx5_ib_odp_cleanup_one(struct mlx5_ib_dev *ibdev);
 int __init mlx5_ib_odp_init(void);
 void mlx5_ib_odp_cleanup(void);
+#ifndef HAVE_MMU_INTERVAL_NOTIFIER
+void mlx5_ib_invalidate_range(struct ib_umem_odp *umem_odp, unsigned long start,
+			      unsigned long end);
+#endif
 int mlx5_odp_init_mkey_cache(struct mlx5_ib_dev *dev);
 void mlx5_odp_populate_xlt(void *xlt, size_t idx, size_t nentries,
 			   struct mlx5_ib_mr *mr, int flags);
@@ -1478,10 +1486,17 @@ static inline int mlx5_ib_init_dmabuf_mr
 {
 	return -EOPNOTSUPP;
 }
+#ifndef HAVE_MMU_INTERVAL_NOTIFIER
+static inline void mlx5_ib_invalidate_range(struct ib_umem_odp *umem_odp,
+					    unsigned long start,
+					    unsigned long end){};
+#endif
 #endif /* CONFIG_INFINIBAND_ON_DEMAND_PAGING */
 
+#ifdef HAVE_MMU_INTERVAL_NOTIFIER
 extern const struct mmu_interval_notifier_ops mlx5_mn_ops;
 
+#endif
 /* Needed for rep profile */
 void __mlx5_ib_remove(struct mlx5_ib_dev *dev,
 		      const struct mlx5_ib_profile *profile,
