From: Israel Rukshin <israelr@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/nvme/host/multipath.c

Change-Id: Ie81b70d5e2a7ef05e97ca7f1bb43378ab0b20bca
---
 drivers/nvme/host/multipath.c | 79 ++++++++++++++++++++++++++++++++++-
 1 file changed, 78 insertions(+), 1 deletion(-)

--- a/drivers/nvme/host/multipath.c
+++ b/drivers/nvme/host/multipath.c
@@ -3,6 +3,8 @@
  * Copyright (c) 2017-2018 Christoph Hellwig.
  */
 
+#ifdef HAVE_BLK_TYPES_REQ_DRV
+
 #include <linux/moduleparam.h>
 #include <trace/events/block.h>
 #include "nvme.h"
@@ -282,10 +284,22 @@ static bool nvme_available_path(struct n
 	return false;
 }
 
+#ifdef HAVE_BLOCK_DEVICE_OPERATIONS_SUBMIT_BIO
+blk_qc_t nvme_ns_head_submit_bio(struct bio *bio)
+#else
 static blk_qc_t nvme_ns_head_make_request(struct request_queue *q,
 		struct bio *bio)
+#endif
 {
+#ifdef HAVE_BLOCK_DEVICE_OPERATIONS_SUBMIT_BIO
+#ifdef HAVE_BIO_BI_DISK
+	struct nvme_ns_head *head = bio->bi_disk->private_data;
+#else
+	struct nvme_ns_head *head = bio->bi_bdev->bd_disk->private_data;
+#endif
+#else
 	struct nvme_ns_head *head = q->queuedata;
+#endif
 	struct device *dev = disk_to_dev(head->disk);
 	struct nvme_ns *ns;
 	blk_qc_t ret = BLK_QC_T_NONE;
@@ -297,7 +311,11 @@ static blk_qc_t nvme_ns_head_make_reques
 	 * so we need to use the bio_split pool from the original
 	 * queue to allocate the bvecs from.
 	 */
+#ifdef HAVE_BLK_QUEUE_SPLIT_1_PARAM
+	blk_queue_split(&bio);
+#else
 	blk_queue_split(q, &bio);
+#endif
 
 	srcu_idx = srcu_read_lock(&head->srcu);
 	ns = nvme_find_path(head);
@@ -307,7 +325,11 @@ static blk_qc_t nvme_ns_head_make_reques
 		trace_block_bio_remap(bio->bi_disk->queue, bio,
 				      disk_devt(ns->head->disk),
 				      bio->bi_iter.bi_sector);
+#ifdef HAVE_SUBMIT_BIO_NOACCT
+		ret = submit_bio_noacct(bio);
+#else
 		ret = direct_make_request(bio);
+#endif
 	} else if (nvme_available_path(head)) {
 		dev_warn_ratelimited(dev, "no usable path - requeuing I/O\n");
 
@@ -344,7 +366,11 @@ static void nvme_requeue_work(struct wor
 		 * path.
 		 */
 		bio->bi_disk = head->disk;
+#ifdef HAVE_SUBMIT_BIO_NOACCT
+		submit_bio_noacct(bio);
+#else
 		generic_make_request(bio);
+#endif
 	}
 }
 
@@ -366,11 +392,29 @@ int nvme_mpath_alloc_disk(struct nvme_ct
 	if (!(ctrl->subsys->cmic & (1 << 1)) || !multipath)
 		return 0;
 
+#ifdef HAVE_BLOCK_DEVICE_OPERATIONS_SUBMIT_BIO
+        q = blk_alloc_queue(ctrl->numa_node);
+#else
+#ifdef HAVE_BLK_QUEUE_MAKE_REQUEST
+#ifdef HAVE_BLK_ALLOC_QUEUE_NODE_3_ARGS
+	q = blk_alloc_queue_node(GFP_KERNEL, NUMA_NO_NODE, NULL);
+#else
+#ifdef HAVE_BLK_ALLOC_QUEUE_RH
+	q = blk_alloc_queue_rh(nvme_ns_head_make_request, ctrl->numa_node);
+#else
 	q = blk_alloc_queue_node(GFP_KERNEL, ctrl->numa_node);
+#endif
+#endif
+#else
+	q = blk_alloc_queue(nvme_ns_head_make_request, ctrl->numa_node);
+#endif
+#endif /* HAVE_BLOCK_DEVICE_OPERATIONS_SUBMIT_BIO */
 	if (!q)
 		goto out;
 	q->queuedata = head;
+#if defined(HAVE_BLK_QUEUE_MAKE_REQUEST) && !defined(HAVE_BLK_ALLOC_QUEUE_RH)
 	blk_queue_make_request(q, nvme_ns_head_make_request);
+#endif
 	blk_queue_flag_set(QUEUE_FLAG_NONROT, q);
 	/* set to a default value for 512 until disk is validated */
 	blk_queue_logical_block_size(q, 512);
@@ -407,9 +451,19 @@ static void nvme_mpath_set_live(struct n
 	if (!head->disk)
 		return;
 
+#ifdef HAVE_DEVICE_ADD_DISK_3_ARGS
 	if (!(head->disk->flags & GENHD_FL_UP))
 		device_add_disk(&head->subsys->dev, head->disk,
 				nvme_ns_id_attr_groups);
+#else
+	if (!(head->disk->flags & GENHD_FL_UP)) {
+		device_add_disk(&head->subsys->dev, head->disk);
+		if (sysfs_create_group(&disk_to_dev(head->disk)->kobj,
+				&nvme_ns_id_attr_group))
+			dev_warn(&head->subsys->dev,
+				 "failed to create id group.\n");
+	}
+#endif
 
 	if (nvme_path_is_optimized(ns)) {
 		int node, srcu_idx;
@@ -560,9 +614,15 @@ static void nvme_ana_work(struct work_st
 	nvme_read_ana_log(ctrl, false);
 }
 
+#ifdef HAVE_TIMER_SETUP
 static void nvme_anatt_timeout(struct timer_list *t)
 {
 	struct nvme_ctrl *ctrl = from_timer(ctrl, t, anatt_timer);
+#else
+static void nvme_anatt_timeout(unsigned long data)
+{
+	struct nvme_ctrl *ctrl = (struct nvme_ctrl *)data;
+#endif
 
 	dev_info(ctrl->device, "ANATT timeout, resetting controller.\n");
 	nvme_reset_ctrl(ctrl);
@@ -662,8 +722,16 @@ void nvme_mpath_remove_disk(struct nvme_
 {
 	if (!head->disk)
 		return;
+#ifdef HAVE_DEVICE_ADD_DISK_3_ARGS
 	if (head->disk->flags & GENHD_FL_UP)
 		del_gendisk(head->disk);
+#else
+	if (head->disk->flags & GENHD_FL_UP) {
+		sysfs_remove_group(&disk_to_dev(head->disk)->kobj,
+				   &nvme_ns_id_attr_group);
+		del_gendisk(head->disk);
+	}
+#endif
 	blk_set_queue_dying(head->disk->queue);
 	/* make sure all pending bios are cleaned up */
 	kblockd_schedule_work(&head->requeue_work);
@@ -686,7 +754,11 @@ int nvme_mpath_init(struct nvme_ctrl *ct
 	ctrl->anagrpmax = le32_to_cpu(id->anagrpmax);
 
 	mutex_init(&ctrl->ana_lock);
+#ifdef HAVE_TIMER_SETUP
 	timer_setup(&ctrl->anatt_timer, nvme_anatt_timeout, 0);
+#else
+	init_timer(&ctrl->anatt_timer);
+#endif
 	ctrl->ana_log_size = sizeof(struct nvme_ana_rsp_hdr) +
 		ctrl->nanagrpid * sizeof(struct nvme_ana_group_desc);
 	ctrl->ana_log_size += ctrl->max_namespaces * sizeof(__le32);
@@ -701,6 +773,10 @@ int nvme_mpath_init(struct nvme_ctrl *ct
 	}
 
 	INIT_WORK(&ctrl->ana_work, nvme_ana_work);
+#ifndef HAVE_TIMER_SETUP
+	ctrl->anatt_timer.data = (unsigned long)ctrl;
+	ctrl->anatt_timer.function = nvme_anatt_timeout;
+#endif
 	ctrl->ana_log_buf = kmalloc(ctrl->ana_log_size, GFP_KERNEL);
 	if (!ctrl->ana_log_buf) {
 		error = -ENOMEM;
@@ -723,4 +799,5 @@ void nvme_mpath_uninit(struct nvme_ctrl
 	kfree(ctrl->ana_log_buf);
 	ctrl->ana_log_buf = NULL;
 }
+#endif /* HAVE_BLK_TYPES_REQ_DRV */
 
