From: Shay Drory <shayd@nvidia.com>
Subject: [PATCH] BACKPORT:
 drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c

Change-Id: I8656f954e3f59d68c99d0fd96e525251a96a198f
---
 .../mellanox/mlx5/core/eswitch_offloads.c     | 323 +++++++++++++++++-
 1 file changed, 308 insertions(+), 15 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@ -2536,6 +2536,7 @@ err:
 	return err;
 }
 
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) || defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
 static int esw_port_metadata_set(struct devlink *devlink, u32 id,
 				 struct devlink_param_gset_ctx *ctx)
 {
@@ -2594,6 +2595,7 @@ static const struct devlink_param esw_de
 			     esw_port_metadata_set,
 			     esw_port_metadata_validate),
 };
+#endif
 
 int esw_offloads_init(struct mlx5_eswitch *esw)
 {
@@ -2603,24 +2605,38 @@ int esw_offloads_init(struct mlx5_eswitc
 	if (err)
 		return err;
 
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) || defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	err = devl_params_register(priv_to_devlink(esw->dev),
+#else
+	err = devlink_params_register(priv_to_devlink(esw->dev),
+#endif
 				   esw_devlink_params,
 				   ARRAY_SIZE(esw_devlink_params));
 	if (err)
 		goto err_params;
+#endif
 
 	return 0;
 
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) || defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
 err_params:
 	esw_offloads_cleanup_reps(esw);
 	return err;
+#endif
 }
 
 void esw_offloads_cleanup(struct mlx5_eswitch *esw)
 {
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) || defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	devl_params_unregister(priv_to_devlink(esw->dev),
+#else
+	devlink_params_unregister(priv_to_devlink(esw->dev),
+#endif
 			       esw_devlink_params,
 			       ARRAY_SIZE(esw_devlink_params));
+#endif
 	esw_offloads_cleanup_reps(esw);
 }
 
@@ -2682,11 +2698,13 @@ int esw_offloads_load_rep(struct mlx5_es
 	if (esw->mode != MLX5_ESWITCH_OFFLOADS)
 		return 0;
 
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK) {
 		err = mlx5_esw_offloads_devlink_port_register(esw, vport_num);
 		if (err)
 			return err;
 	}
+#endif
 
 	err = mlx5_esw_offloads_rep_load(esw, vport_num);
 	if (err)
@@ -2694,8 +2712,10 @@ int esw_offloads_load_rep(struct mlx5_es
 	return err;
 
 load_err:
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK)
 		mlx5_esw_offloads_devlink_port_unregister(esw, vport_num);
+#endif
 	return err;
 }
 
@@ -2706,8 +2726,10 @@ void esw_offloads_unload_rep(struct mlx5
 
 	mlx5_esw_offloads_rep_unload(esw, vport_num);
 
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK)
 		mlx5_esw_offloads_devlink_port_unregister(esw, vport_num);
+#endif
 }
 
 static int esw_set_slave_root_fdb(struct mlx5_core_dev *master,
@@ -3225,7 +3247,11 @@ u32 mlx5_esw_match_metadata_alloc(struct
 
 	/* Metadata is 4 bits of PFNUM and 12 bits of unique id */
 	/* Use only non-zero vport_id (2-4095) for all PF's */
+#ifdef HAVE_IDA_ALLOC_RANGE
 	id = ida_alloc_range(&esw->offloads.vport_metadata_ida,
+#else
+	id = ida_simple_get(&esw->offloads.vport_metadata_ida,
+#endif
 			     MLX5_ESW_METADATA_RSVD_UPLINK + 1,
 			     vport_end_ida, GFP_KERNEL);
 	if (id < 0)
@@ -3239,7 +3265,11 @@ void mlx5_esw_match_metadata_free(struct
 	u32 vport_bit_mask = (1 << ESW_VPORT_BITS) - 1;
 
 	/* Metadata contains only 12 bits of actual ida id */
-	ida_free(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#ifdef HAVE_IDA_FREE
+       ida_free(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#else
+	ida_simple_remove(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#endif
 }
 
 static int esw_offloads_vport_metadata_setup(struct mlx5_eswitch *esw,
@@ -3480,7 +3510,9 @@ static void esw_offloads_steering_cleanu
 static void
 esw_vfs_changed_event_handler(struct mlx5_eswitch *esw, const u32 *out)
 {
+#ifdef HAVE_DEVL_PORT_REGISTER
 	struct devlink *devlink;
+#endif
 	bool host_pf_disabled;
 	u16 new_num_vfs;
 
@@ -3492,8 +3524,10 @@ esw_vfs_changed_event_handler(struct mlx
 	if (new_num_vfs == esw->esw_funcs.num_vfs || host_pf_disabled)
 		return;
 
+#ifdef HAVE_DEVL_PORT_REGISTER
 	devlink = priv_to_devlink(esw->dev);
 	devl_lock(devlink);
+#endif
 	/* Number of VFs can only change from "0 to x" or "x to 0". */
 	if (esw->esw_funcs.num_vfs > 0) {
 		mlx5_eswitch_unload_vf_vports(esw, esw->esw_funcs.num_vfs);
@@ -3503,12 +3537,16 @@ esw_vfs_changed_event_handler(struct mlx
 		err = mlx5_eswitch_load_vf_vports(esw, new_num_vfs,
 						  MLX5_VPORT_UC_ADDR_CHANGE);
 		if (err) {
+#ifdef HAVE_DEVL_PORT_REGISTER
 			devl_unlock(devlink);
+#endif
 			return;
 		}
 	}
 	esw->esw_funcs.num_vfs = new_num_vfs;
+#ifdef HAVE_DEVL_PORT_REGISTER
 	devl_unlock(devlink);
+#endif
 }
 
 static void esw_functions_changed_event_handler(struct work_struct *work)
@@ -3824,17 +3862,25 @@ bool mlx5_eswitch_mode_is_blocked(struct
 	return blocked;
 }
 
-int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode,
-				  struct netlink_ext_ack *extack)
+int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				  , struct netlink_ext_ack *extack
+#endif
+				  )
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack = NULL;
+#endif
 	u16 cur_mlx5_mode, mlx5_mode = 0;
 	struct mlx5_eswitch *esw;
 	int err = 0;
 
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) || defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
 	if (mlx5_dev_is_lightweight(devlink_priv(devlink))) {
 		NL_SET_ERR_MSG_MOD(extack, "Function doesn't fully probe.");
 		return -EOPNOTSUPP;
 	}
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -3881,12 +3927,14 @@ int mlx5_devlink_eswitch_mode_set(struct
 
 	mlx5_eswitch_disable_locked(esw);
 	if (mode == DEVLINK_ESWITCH_MODE_SWITCHDEV) {
+#ifdef HAVE_DEVLINK_TRAP_SUPPORT
 		if (mlx5_devlink_trap_get_num_active(esw->dev)) {
 			NL_SET_ERR_MSG_MOD(extack,
 					   "Can't change mode while devlink traps are active");
 			err = -EOPNOTSUPP;
 			goto skip;
 		}
+#endif
 		err = esw_offloads_start(esw, extack);
 	} else if (mode == DEVLINK_ESWITCH_MODE_LEGACY) {
 		err = esw_offloads_stop(esw, extack);
@@ -3895,7 +3943,9 @@ int mlx5_devlink_eswitch_mode_set(struct
 		err = -EINVAL;
 	}
 
+#ifdef HAVE_DEVLINK_TRAP_SUPPORT
 skip:
+#endif
 	down_write(&esw->mode_lock);
 	esw->eswitch_operation_in_progress = false;
 unlock:
@@ -3966,14 +4016,23 @@ revert_inline_mode:
 	return err;
 }
 
-int mlx5_devlink_eswitch_inline_mode_set(struct devlink *devlink, u8 mode,
-					 struct netlink_ext_ack *extack)
+int mlx5_devlink_eswitch_inline_mode_set(struct devlink *devlink, u8 mode
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 	, struct netlink_ext_ack *extack
+#endif
+				 	)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw;
 	u8 mlx5_mode;
 	int err;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
@@ -4067,13 +4126,26 @@ void mlx5_eswitch_unblock_encap(struct m
 }
 
 int mlx5_devlink_eswitch_encap_mode_set(struct devlink *devlink,
-					enum devlink_eswitch_encap_mode encap,
-					struct netlink_ext_ack *extack)
+#ifdef HAVE_DEVLINK_HAS_ESWITCH_ENCAP_MODE_SET_GET_WITH_ENUM
+					enum devlink_eswitch_encap_mode encap
+#else
+					u8 encap
+#endif
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 	, struct netlink_ext_ack *extack
+#endif
+				 	)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw;
 	int err = 0;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
@@ -4139,7 +4211,11 @@ unlock:
 }
 
 int mlx5_devlink_eswitch_encap_mode_get(struct devlink *devlink,
+#ifdef HAVE_DEVLINK_HAS_ESWITCH_ENCAP_MODE_SET_GET_WITH_ENUM
 					enum devlink_eswitch_encap_mode *encap)
+#else
+					u8 *encap)
+#endif
 {
 	struct mlx5_eswitch *esw;
 
@@ -4168,14 +4244,24 @@ mlx5_eswitch_vport_has_rep(const struct
 }
 
 int mlx5_devlink_eswitch_ipsec_mode_set(struct devlink *devlink,
-					enum devlink_eswitch_ipsec_mode ipsec,
-					struct netlink_ext_ack *extack)
+					enum devlink_eswitch_ipsec_mode ipsec
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+					, struct netlink_ext_ack *extack
+#endif
+					)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw = dev->priv.eswitch;
 	int err = 0;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#else
 	memset(extack, 0, sizeof(*extack));
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -4637,15 +4723,24 @@ is_port_function_supported(struct mlx5_e
 	       mlx5_esw_is_sf_vport(esw, vport_num);
 }
 
-int mlx5_devlink_port_function_hw_addr_get(struct devlink_port *port,
-					   u8 *hw_addr, int *hw_addr_len,
-					   struct netlink_ext_ack *extack)
+#if defined(HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM) || defined(HAVE_DEVLINK_PORT_OPS)
+int mlx5_devlink_port_function_hw_addr_get(
+#else
+int mlx5_devlink_port_function_hw_addr_get(struct devlink *devlink,
+#endif
+ 					   struct devlink_port *port,
+ 					   u8 *hw_addr, int *hw_addr_len,
+ 					   struct netlink_ext_ack *extack)
 {
 	struct mlx5_eswitch *esw;
 	struct mlx5_vport *vport;
 	u16 vport_num;
 
+#if defined(HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM) || defined(HAVE_DEVLINK_PORT_OPS)
 	esw = mlx5_devlink_eswitch_get(port->devlink);
+#else
+	esw = mlx5_devlink_eswitch_get(devlink);
+#endif
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
 
@@ -4666,14 +4761,23 @@ int mlx5_devlink_port_function_hw_addr_g
 	return 0;
 }
 
-int mlx5_devlink_port_function_hw_addr_set(struct devlink_port *port,
-					   const u8 *hw_addr, int hw_addr_len,
-					   struct netlink_ext_ack *extack)
+#if defined(HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM) || defined(HAVE_DEVLINK_PORT_OPS)
+int mlx5_devlink_port_function_hw_addr_set(
+#else
+int mlx5_devlink_port_function_hw_addr_set(struct devlink *devlink,
+#endif
+ 					   struct devlink_port *port,
+ 					   const u8 *hw_addr, int hw_addr_len,
+ 					   struct netlink_ext_ack *extack)
 {
 	struct mlx5_eswitch *esw;
 	u16 vport_num;
 
+#if defined(HAVE_PORT_FUNCTION_HW_ADDR_GET_GET_4_PARAM) || defined(HAVE_DEVLINK_PORT_OPS)
 	esw = mlx5_devlink_eswitch_get(port->devlink);
+#else
+	esw = mlx5_devlink_eswitch_get(devlink);
+#endif
 	if (IS_ERR(esw)) {
 		NL_SET_ERR_MSG_MOD(extack, "Eswitch doesn't support set hw_addr");
 		return PTR_ERR(esw);
@@ -4688,6 +4792,7 @@ int mlx5_devlink_port_function_hw_addr_s
 	return mlx5_eswitch_set_vport_mac(esw, vport_num, hw_addr);
 }
 
+#if defined(HAVE_DEVLINK_HAS_PORT_FN_ROCE_MIG) || defined(HAVE_DEVLINK_PORT_OPS)
 static struct mlx5_vport *
 mlx5_devlink_port_fn_get_vport(struct devlink_port *port, struct mlx5_eswitch *esw)
 {
@@ -4892,6 +4997,7 @@ out:
 	mutex_unlock(&esw->state_lock);
 	return err;
 }
+#endif // HAVE_DEVLINK_HAS_PORT_FN_ROCE_MIG
 
 int
 mlx5_eswitch_restore_ipsec_rule(struct mlx5_eswitch *esw, struct mlx5_flow_handle *rule,
@@ -4908,3 +5014,190 @@ mlx5_eswitch_restore_ipsec_rule(struct m
 
 	return mlx5_modify_rule_destination(rule, &new_dest, &old_dest);
 }
+#ifdef CONFIG_XFRM_OFFLOAD
+#ifdef HAVE_DEVLINK_IPSEC_CRYPTO
+int mlx5_devlink_port_fn_ipsec_crypto_get(struct devlink_port *port, bool *is_enabled,
+					  struct netlink_ext_ack *extack)
+{
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	int err = 0;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	if (!mlx5_esw_ipsec_vf_offload_supported(esw->dev)) {
+		NL_SET_ERR_MSG_MOD(extack, "Device doesn't support IPSec crypto");
+		return -EOPNOTSUPP;
+	}
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+
+	mutex_lock(&esw->state_lock);
+	if (!vport->enabled) {
+		err = -EOPNOTSUPP;
+		goto unlock;
+	}
+
+	*is_enabled = vport->info.ipsec_crypto_enabled;
+unlock:
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+
+int mlx5_devlink_port_fn_ipsec_crypto_set(struct devlink_port *port, bool enable,
+					  struct netlink_ext_ack *extack)
+{
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	u16 vport_num;
+	int err;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	vport_num = mlx5_esw_devlink_port_index_to_vport_num(port->index);
+	err = mlx5_esw_ipsec_vf_crypto_offload_supported(esw->dev, vport_num);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Device doesn't support IPsec crypto");
+		return err;
+	}
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+
+	mutex_lock(&esw->state_lock);
+	if (!vport->enabled) {
+		err = -EOPNOTSUPP;
+		NL_SET_ERR_MSG_MOD(extack, "Eswitch vport is disabled");
+		goto unlock;
+	}
+
+	if (vport->info.ipsec_crypto_enabled == enable)
+		goto unlock;
+
+	if (!esw->enabled_ipsec_vf_count && esw->dev->num_ipsec_offloads) {
+		err = -EBUSY;
+		goto unlock;
+	}
+
+	err = mlx5_esw_ipsec_vf_crypto_offload_set(esw, vport, enable);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack, "Failed to set IPsec crypto");
+		goto unlock;
+	}
+
+	vport->info.ipsec_crypto_enabled = enable;
+	if (enable)
+		esw->enabled_ipsec_vf_count++;
+	else
+		esw->enabled_ipsec_vf_count--;
+unlock:
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+#endif /* HAVE_DEVLINK_IPSEC_CRYPTO */
+#ifdef HAVE_DEVLINK_IPSEC_PACKET
+int mlx5_devlink_port_fn_ipsec_packet_get(struct devlink_port *port, bool *is_enabled,
+					  struct netlink_ext_ack *extack)
+{
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	int err = 0;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	if (!mlx5_esw_ipsec_vf_offload_supported(esw->dev)) {
+		NL_SET_ERR_MSG_MOD(extack, "Device doesn't support IPsec packet");
+		return -EOPNOTSUPP;
+	}
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+
+	mutex_lock(&esw->state_lock);
+	if (!vport->enabled) {
+		err = -EOPNOTSUPP;
+		goto unlock;
+	}
+
+	*is_enabled = vport->info.ipsec_packet_enabled;
+unlock:
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+
+int mlx5_devlink_port_fn_ipsec_packet_set(struct devlink_port *port,
+					  bool enable,
+					  struct netlink_ext_ack *extack)
+{
+	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
+	u16 vport_num;
+	int err;
+
+	esw = mlx5_devlink_eswitch_get(port->devlink);
+	if (IS_ERR(esw))
+		return PTR_ERR(esw);
+
+	vport_num = mlx5_esw_devlink_port_index_to_vport_num(port->index);
+	err = mlx5_esw_ipsec_vf_packet_offload_supported(esw->dev, vport_num);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Device doesn't support IPsec packet mode");
+		return err;
+	}
+
+	vport = mlx5_devlink_port_fn_get_vport(port, esw);
+	if (IS_ERR(vport)) {
+		NL_SET_ERR_MSG_MOD(extack, "Invalid port");
+		return PTR_ERR(vport);
+	}
+	mutex_lock(&esw->state_lock);
+	if (!vport->enabled) {
+		err = -EOPNOTSUPP;
+		NL_SET_ERR_MSG_MOD(extack, "Eswitch vport is disabled");
+		goto unlock;
+	}
+
+	if (vport->info.ipsec_packet_enabled == enable)
+		goto unlock;
+
+	if (!esw->enabled_ipsec_vf_count && esw->dev->num_ipsec_offloads) {
+		err = -EBUSY;
+		goto unlock;
+	}
+
+	err = mlx5_esw_ipsec_vf_packet_offload_set(esw, vport, enable);
+	if (err) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Failed to set IPsec packet mode");
+		goto unlock;
+	}
+
+	vport->info.ipsec_packet_enabled = enable;
+	if (enable)
+		esw->enabled_ipsec_vf_count++;
+	else
+		esw->enabled_ipsec_vf_count--;
+unlock:
+	mutex_unlock(&esw->state_lock);
+	return err;
+}
+#endif /* HAVE_DEVLINK_IPSEC_PACKET */
+#endif /* CONFIG_XFRM_OFFLOAD */
