From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h

Change-Id: I9b4df1b8d54fd3294bc5378a93f2716b287998da
---
 drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
@@ -50,17 +50,29 @@ struct mlx5e_xdp_buff {
 	struct mlx5e_rq *rq;
 };
 
+#ifdef HAVE_XDP_SUPPORT
 struct mlx5e_xsk_param;
 int mlx5e_xdp_max_mtu(struct mlx5e_params *params, struct mlx5e_xsk_param *xsk);
 bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_alloc_unit *au,
 		      struct bpf_prog *prog, struct mlx5e_xdp_buff *mlctx);
+#ifndef HAVE_XSK_BUFF_ALLOC
+bool mlx5e_xdp_handle_old(struct mlx5e_rq *rq, struct mlx5e_alloc_unit *au,
+		      struct bpf_prog *prog, struct xdp_buff *xdp);
+#endif
 void mlx5e_xdp_mpwqe_complete(struct mlx5e_xdpsq *sq);
 bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq);
 void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq);
 void mlx5e_set_xmit_fp(struct mlx5e_xdpsq *sq, bool is_mpw);
 void mlx5e_xdp_rx_poll_complete(struct mlx5e_rq *rq);
+#ifdef HAVE_NDO_XDP_XMIT
+#ifndef HAVE_NDO_XDP_FLUSH
 int mlx5e_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
 		   u32 flags);
+#else
+int mlx5e_xdp_xmit(struct net_device *dev, struct xdp_buff *xdp);
+void mlx5e_xdp_flush(struct net_device *dev);
+#endif
+#endif
 
 extern const struct xdp_metadata_ops mlx5e_xdp_metadata_ops;
 
@@ -110,7 +122,6 @@ static inline void mlx5e_xmit_xdp_doorbe
 		sq->doorbell_cseg = NULL;
 	}
 }
-
 /* Enable inline WQEs to shift some load from a congested HCA (HW) to
  * a less congested cpu (SW).
  */
@@ -192,3 +203,4 @@ mlx5e_xdpi_fifo_pop(struct mlx5e_xdp_inf
 	return fifo->xi[(*fifo->cc)++ & fifo->mask];
 }
 #endif
+#endif
