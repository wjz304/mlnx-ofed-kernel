From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/fw_reset.c

Change-Id: I9a6fa4dbe5308a1e4c6b71b016cf92d3114f338f
---
 .../ethernet/mellanox/mlx5/core/fw_reset.c    | 127 ++++++++++++++++++
 1 file changed, 127 insertions(+)

--- a/drivers/net/ethernet/mellanox/mlx5/core/fw_reset.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fw_reset.c
@@ -28,8 +28,10 @@ struct mlx5_fw_reset {
 	struct delayed_work reset_timeout_work;
 	unsigned long reset_flags;
 	struct timer_list timer;
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 	struct completion done;
 	int ret;
+#endif
 };
 
 enum {
@@ -52,12 +54,17 @@ static void mlx5_set_fw_rst_ack(struct m
 	iowrite32be(BIT(MLX5_RST_ACK_BIT_NUM), &dev->iseg->initializing);
 }
 
+#if defined(HAVE_DEVLINK_PARAM) && (defined(HAVE_DEVLINK_PARAMS_PUBLISHED) || defined(HAVE_DEVLINK_REGISTER_GET_1_PARAMS))
 static int mlx5_fw_reset_enable_remote_dev_reset_set(struct devlink *devlink, u32 id,
 						     struct devlink_param_gset_ctx *ctx)
 {
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_fw_reset *fw_reset;
 
+	#if !defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET) && defined(HAVE_DEVLINK_PARAM_REGISTER)
+        	if (mlx5_dev_is_lightweight(dev))
+                	return -EOPNOTSUPP;
+	#endif
 	fw_reset = dev->priv.fw_reset;
 
 	if (ctx->val.vbool)
@@ -73,12 +80,17 @@ static int mlx5_fw_reset_enable_remote_d
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_fw_reset *fw_reset;
 
+	#if !defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET) && defined(HAVE_DEVLINK_PARAM_REGISTER)
+        	if (mlx5_dev_is_lightweight(dev))
+                	return -EOPNOTSUPP;
+	#endif
 	fw_reset = dev->priv.fw_reset;
 
 	ctx->val.vbool = !test_bit(MLX5_FW_RESET_FLAGS_NACK_RESET_REQUEST,
 				   &fw_reset->reset_flags);
 	return 0;
 }
+#endif
 
 static int mlx5_reg_mfrl_set(struct mlx5_core_dev *dev, u8 reset_level,
 			     u8 reset_type_sel, u8 sync_resp, bool sync_start)
@@ -120,6 +132,7 @@ int mlx5_fw_reset_query(struct mlx5_core
 	return mlx5_reg_mfrl_query(dev, reset_level, reset_type, NULL);
 }
 
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 static int mlx5_fw_reset_get_reset_state_err(struct mlx5_core_dev *dev,
 					     struct netlink_ext_ack *extack)
 {
@@ -171,12 +184,14 @@ int mlx5_fw_reset_set_reset_sync(struct
 	NL_SET_ERR_MSG_MOD(extack, "Sync reset command failed");
 	return mlx5_cmd_check(dev, err, in, out);
 }
+#endif /* HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION */
 
 int mlx5_fw_reset_set_live_patch(struct mlx5_core_dev *dev)
 {
 	return mlx5_reg_mfrl_set(dev, MLX5_MFRL_REG_RESET_LEVEL0, 0, 0, false);
 }
 
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 static void mlx5_fw_reset_complete_reload(struct mlx5_core_dev *dev, bool unloaded)
 {
 	struct mlx5_fw_reset *fw_reset = dev->priv.fw_reset;
@@ -185,17 +200,20 @@ static void mlx5_fw_reset_complete_reloa
 	if (test_bit(MLX5_FW_RESET_FLAGS_PENDING_COMP, &fw_reset->reset_flags)) {
 		complete(&fw_reset->done);
 	} else {
+#ifdef HAVE_DEVL_TRAP_GROUPS_REGISTER
 		if (!unloaded)
 			mlx5_unload_one(dev, false);
 		if (mlx5_health_wait_pci_up(dev))
 			mlx5_core_err(dev, "reset reload flow aborted, PCI reads still not working\n");
 		else
+#endif
 			mlx5_load_one(dev, true);
 		devlink_remote_reload_actions_performed(priv_to_devlink(dev), 0,
 							BIT(DEVLINK_RELOAD_ACTION_DRIVER_REINIT) |
 							BIT(DEVLINK_RELOAD_ACTION_FW_ACTIVATE));
 	}
 }
+#endif
 
 static void mlx5_stop_sync_reset_poll(struct mlx5_core_dev *dev)
 {
@@ -224,17 +242,46 @@ static void mlx5_sync_reset_reload_work(
 	struct mlx5_fw_reset *fw_reset = container_of(work, struct mlx5_fw_reset,
 						      reset_reload_work);
 	struct mlx5_core_dev *dev = fw_reset->dev;
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	int err;
+#endif
 
 	cancel_delayed_work(&fw_reset->reset_timeout_work);
 	mlx5_sync_reset_clear_reset_requested(dev, false);
 	mlx5_enter_error_state(dev, true);
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	mlx5_unload_one(dev, false);
+	err = mlx5_health_wait_pci_up(dev);
+	if (err) {
+		mlx5_core_err(dev, "reset reload flow aborted, PCI reads still not working\n");
+#ifndef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
+		return;
+#endif
+	}
+#endif /* HAVE_DEVL_TRAP_GROUPS_REGISTER */
+
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	fw_reset->ret = err;
+#endif
 	mlx5_fw_reset_complete_reload(dev, false);
+#else /* HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION */
+	mlx5_load_one(dev, true);
+#endif /* HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION */
 }
 
 #define MLX5_RESET_POLL_INTERVAL	(HZ / 10)
+#ifdef HAVE_TIMER_SETUP
 static void poll_sync_reset(struct timer_list *t)
+#else
+static void poll_sync_reset(unsigned long data)
+#endif
 {
+#ifdef HAVE_TIMER_SETUP
 	struct mlx5_fw_reset *fw_reset = from_timer(fw_reset, t, timer);
+#else
+	struct mlx5_fw_reset *fw_reset = (struct mlx5_fw_reset *)data;
+#endif
 	struct mlx5_core_dev *dev = fw_reset->dev;
 	u32 fatal_error;
 
@@ -259,7 +306,13 @@ static void mlx5_start_sync_reset_poll(s
 {
 	struct mlx5_fw_reset *fw_reset = dev->priv.fw_reset;
 
+#ifdef HAVE_TIMER_SETUP
 	timer_setup(&fw_reset->timer, poll_sync_reset, 0);
+#else
+	init_timer(&fw_reset->timer);
+	fw_reset->timer.data = (unsigned long)fw_reset;
+	fw_reset->timer.function = poll_sync_reset;
+#endif
 	fw_reset->timer.expires = round_jiffies(jiffies + MLX5_RESET_POLL_INTERVAL);
 	add_timer(&fw_reset->timer);
 }
@@ -417,6 +470,10 @@ static void mlx5_sync_reset_request_even
 		mlx5_core_warn(dev, "PCI Sync FW Update Reset Ack. Device reset is expected.\n");
 }
 
+#ifndef PCI_EXP_RTCAP_CRSVIS
+#define  PCI_EXP_RTCAP_CRSVIS	0x0001	/* CRS Software Visibility capability */
+#endif
+
 static int mlx5_pci_config_hw_control(struct pci_dev *root_port,
 				      bool new_val, bool *prev_val)
 {
@@ -569,6 +626,20 @@ static int mlx5_reset_pci_topology(struc
 	return 0;
 }
 
+#ifndef HAVE_PCIE_FIND_ROOT_PORT
+static inline struct pci_dev *pcie_find_root_port(struct pci_dev *dev)
+{
+	while (dev) {
+		if (pci_is_pcie(dev) &&
+		    pci_pcie_type(dev) == PCI_EXP_TYPE_ROOT_PORT)
+			return dev;
+		dev = pci_upstream_bridge(dev);
+	}
+
+	return NULL;
+}
+#endif
+
 static int mlx5_pci_link_toggle_ecpf(struct mlx5_core_dev *dev)
 {
 	struct pci_dev *root_port;
@@ -734,9 +805,16 @@ static void mlx5_sync_reset_now_event(st
 	}
 
 	mlx5_enter_error_state(dev, true);
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	mlx5_unload_one(dev, false);
+#endif
 done:
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 	fw_reset->ret = err;
 	mlx5_fw_reset_complete_reload(dev, false);
+#else
+	mlx5_load_one(dev, true);
+#endif
 }
 
 static void mlx5_sync_reset_unload_event(struct work_struct *work)
@@ -763,9 +841,11 @@ static void mlx5_sync_reset_unload_event
 	else
 		mlx5_enter_error_state(dev, true);
 
+#ifdef HAVE_DEVL_TRAP_GROUPS_REGISTER
 	if (test_bit(MLX5_FW_RESET_FLAGS_PENDING_COMP, &fw_reset->reset_flags))
 		mlx5_unload_one_devl_locked(dev, false);
 	else
+#endif
 		mlx5_unload_one(dev, false);
 
 	mlx5_set_fw_rst_ack(dev);
@@ -786,7 +866,9 @@ static void mlx5_sync_reset_unload_event
 	if (!reset_action) {
 		mlx5_core_err(dev, "Got timeout waiting for sync reset action, state = %u\n",
 			      rst_state);
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 		fw_reset->ret = -ETIMEDOUT;
+#endif
 		goto done;
 	}
 
@@ -795,12 +877,18 @@ static void mlx5_sync_reset_unload_event
 		err = mlx5_pci_link_toggle(dev);
 		if (err) {
 			mlx5_core_warn(dev, "mlx5_pci_link_toggle failed, err %d\n", err);
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 			fw_reset->ret = err;
+#endif
 		}
 	}
 
 done:
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 	mlx5_fw_reset_complete_reload(dev, true);
+#else /* HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION */
+	mlx5_load_one(dev, true);
+#endif /* HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION */
 }
 
 static void mlx5_sync_reset_abort_event(struct work_struct *work)
@@ -873,6 +961,7 @@ static int fw_reset_event_notifier(struc
 	return NOTIFY_OK;
 }
 
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 int mlx5_fw_reset_wait_reset_done(struct mlx5_core_dev *dev)
 {
 	unsigned long pci_sync_update_timeout = mlx5_tout_ms(dev, PCI_SYNC_UPDATE);
@@ -891,13 +980,18 @@ int mlx5_fw_reset_wait_reset_done(struct
 	}
 	err = fw_reset->ret;
 	if (test_and_clear_bit(MLX5_FW_RESET_FLAGS_RELOAD_REQUIRED, &fw_reset->reset_flags)) {
+#ifdef HAVE_DEVL_TRAP_GROUPS_REGISTER
 		mlx5_unload_one_devl_locked(dev, false);
 		mlx5_load_one_devl_locked(dev, true);
+#else
+		mlx5_load_one(dev, true);
+#endif
 	}
 out:
 	clear_bit(MLX5_FW_RESET_FLAGS_PENDING_COMP, &fw_reset->reset_flags);
 	return err;
 }
+#endif /* HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION */
 
 void mlx5_fw_reset_events_start(struct mlx5_core_dev *dev)
 {
@@ -926,16 +1020,43 @@ void mlx5_drain_fw_reset(struct mlx5_cor
 	cancel_delayed_work(&fw_reset->reset_timeout_work);
 }
 
+
+#if defined(HAVE_DEVLINK_PARAM) && (defined(HAVE_DEVLINK_PARAMS_PUBLISHED) || defined(HAVE_DEVLINK_REGISTER_GET_1_PARAMS))
 static const struct devlink_param mlx5_fw_reset_devlink_params[] = {
+#ifdef HAVE_DEVLINK_PARAM_GENERIC_ID_ENABLE_REMOTE_DEV_RESET
 	DEVLINK_PARAM_GENERIC(ENABLE_REMOTE_DEV_RESET, BIT(DEVLINK_PARAM_CMODE_RUNTIME),
 			      mlx5_fw_reset_enable_remote_dev_reset_get,
 			      mlx5_fw_reset_enable_remote_dev_reset_set, NULL),
+#else
+	DEVLINK_PARAM_DRIVER(MLX5_DEVLINK_PARAM_ID_ENABLE_REMOTE_DEV_RESET,
+			     "enable_remote_dev_reset", DEVLINK_PARAM_TYPE_BOOL,
+			     BIT(DEVLINK_PARAM_CMODE_RUNTIME),
+			     mlx5_fw_reset_enable_remote_dev_reset_get,
+			     mlx5_fw_reset_enable_remote_dev_reset_set, NULL),
+#endif
 };
 
+#ifndef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
+int mlx5_register_devlink_fw_params(struct mlx5_core_dev *dev)
+{
+	return devlink_params_register(priv_to_devlink(dev), mlx5_fw_reset_devlink_params,
+				       ARRAY_SIZE(mlx5_fw_reset_devlink_params));
+}
+
+void mlx5_unregister_devlink_fw_params(struct mlx5_core_dev *dev)
+{
+	devlink_params_unregister(priv_to_devlink(dev), mlx5_fw_reset_devlink_params,
+				  ARRAY_SIZE(mlx5_fw_reset_devlink_params));
+}
+#endif /* !HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET */
+#endif /* HAVE_DEVLINK_PARAM && (HAVE_DEVLINK_PARAMS_PUBLISHED || HAVE_DEVLINK_REGISTER_GET_1_PARAMS) */
+
 int mlx5_fw_reset_init(struct mlx5_core_dev *dev)
 {
 	struct mlx5_fw_reset *fw_reset = kzalloc(sizeof(*fw_reset), GFP_KERNEL);
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	int err;
+#endif
 
 	if (!fw_reset)
 		return -ENOMEM;
@@ -948,6 +1069,7 @@ int mlx5_fw_reset_init(struct mlx5_core_
 	fw_reset->dev = dev;
 	dev->priv.fw_reset = fw_reset;
 
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	err = devl_params_register(priv_to_devlink(dev),
 				   mlx5_fw_reset_devlink_params,
 				   ARRAY_SIZE(mlx5_fw_reset_devlink_params));
@@ -956,6 +1078,7 @@ int mlx5_fw_reset_init(struct mlx5_core_
 		kfree(fw_reset);
 		return err;
 	}
+#endif
 
 	INIT_WORK(&fw_reset->fw_live_patch_work, mlx5_fw_live_patch_event);
 	INIT_WORK(&fw_reset->reset_request_work, mlx5_sync_reset_request_event);
@@ -965,7 +1088,9 @@ int mlx5_fw_reset_init(struct mlx5_core_
 	INIT_WORK(&fw_reset->reset_abort_work, mlx5_sync_reset_abort_event);
 	INIT_DELAYED_WORK(&fw_reset->reset_timeout_work, mlx5_sync_reset_timeout_work);
 
+#ifdef HAVE_DEVLINK_RELOAD_DOWN_SUPPORT_RELOAD_ACTION
 	init_completion(&fw_reset->done);
+#endif
 	return 0;
 }
 
@@ -973,9 +1098,11 @@ void mlx5_fw_reset_cleanup(struct mlx5_c
 {
 	struct mlx5_fw_reset *fw_reset = dev->priv.fw_reset;
 
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	devl_params_unregister(priv_to_devlink(dev),
 			       mlx5_fw_reset_devlink_params,
 			       ARRAY_SIZE(mlx5_fw_reset_devlink_params));
+#endif
 	destroy_workqueue(fw_reset->wq);
 	kfree(dev->priv.fw_reset);
 }
